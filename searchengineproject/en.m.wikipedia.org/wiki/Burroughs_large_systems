<!doctype html>
	<html lang="en" dir="ltr" class="">
	<head>
		<title>Burroughs large systems - Wikipedia, the free encyclopedia</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="robots" content="noindex,nofollow"/>		<link rel="stylesheet" href="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&amp;lang=en&amp;modules=mobile%7Cmobile.production-only%2Cproduction-jquery%7Cmobile.device.default&amp;only=styles&amp;skin=mobile&amp;version=1352163471&amp;*" />
<link rel="stylesheet" href="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&amp;lang=en&amp;modules=mobile.site&amp;only=styles&amp;skin=mobile&amp;*" />		<meta name="viewport" content="initial-scale=1.0, user-scalable=no">
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />		<script type="text/javascript">
			var _mwStart = +new Date;
			window._evq = window._evq || [];
			if ( typeof console === 'undefined' ) {
				console = { log: function() {} };
			}
			if( typeof mw === 'undefined' ) {
				mw = {};
			}
			var mwMobileFrontendConfig = {"messages":{"mobile-frontend-watchlist-add":"Added $1 to your watchlist","mobile-frontend-watchlist-removed":"Removed $1 from your watchlist","mobile-frontend-watchlist-view":"View your watchlist","mobile-frontend-ajax-random-heading":"Locating knowledge...","mobile-frontend-ajax-random-quote":"Intellectual growth should commence at birth and cease only at death","mobile-frontend-ajax-random-quote-author":"Albert Einstein","mobile-frontend-ajax-random-question":"Read this article?","mobile-frontend-ajax-random-yes":"Yes","mobile-frontend-ajax-random-retry":"Try again","mobile-frontend-ajax-page-loading":"Loading $1","mobile-frontend-page-saving":"Saving $1","mobile-frontend-ajax-page-error":"Whoops! Something went wrong there. Please try refreshing your browser window.","mobile-frontend-meta-data-issues":"This article has some issues","mobile-frontend-meta-data-issues-header":"Issues","expand-section":"Show","collapse-section":"Hide","remove-results":"Back...","mobile-frontend-search-noresults":"No article titles match your search. Change your search, or press the keyboard search button to search inside articles.","mobile-frontend-search-help":"Type search term above and matching article titles will appear here.","contents-heading":"Contents","language-heading":"Read this article in","mobile-frontend-close-section":"Close this section","mobile-frontend-language-footer":"<a href="http://en.m.wikipedia.org/wiki/\&quot;\/wiki\/Special:MobileOptions\/Language\&quot;">Note: This article may not be written in your preferred language. You can see which languages Wikipedia supports by clicking here.<\/a>","mobile-frontend-language-site-choose":"Search language","mobile-frontend-language-site-nomatches":"No matching languages"},"settings":{"action":"","authenticated":false,"scriptPath":"\/w","shim":"\/\/bits.wikimedia.org\/static-1.21wmf3\/extensions\/MobileFrontend\/stylesheets\/common\/images\/blank.gif","pageUrl":"\/wiki\/$1","beta":null,"title":"Burroughs large systems","useFormatCookieName":"mf_mobileFormat","useFormatCookieDuration":-1,"useFormatCookieDomain":"en.wikipedia.org","useFormatCookiePath":"\/","stopMobileRedirectCookieName":"stopMobileRedirect","stopMobileRedirectCookieDuration":15552000,"stopMobileRedirectCookieDomain":".wikipedia.org","hookOptions":""}};
			function _mwLogEvent( data, additionalInformation ) {
				var timestamp = + new Date;
				var ev = { event_id: 'mobile', delta: timestamp - _mwStart, data: data, beta: mwMobileFrontendConfig.settings.beta,
					session: _mwStart, page: mwMobileFrontendConfig.settings.title, info: additionalInformation || '' };
				_evq.push( ev );
				console.log( typeof JSON === 'undefined' ? ev : JSON.stringify( ev ) );
			}
		</script>
				<link rel="canonical" href="http://en.wikipedia.org/wiki/Burroughs_large_systems" >
	</head>
	<body class="mobile live">
				<div id="mw-mf-viewport">
		<div id="mw-mf-page-left">
		<div id='mw-mf-content-left'>
		<ul id="mw-mf-menu-main">
			<li class='icon'><a href="Main_Page"
				title="Home">
				Home</a></li>
			<li class='icon2'><a href="Special:Random#mw-mf-page-left" id="randomButton"
				title="Random"
				class="button">Random</a></li>
						<li class='icon5'>
				<a href="http://en.m.wikipedia.org/w/index.php?title=Special:MobileOptions&amp;returnto=Burroughs+large+systems"
					title="Settings">
				Settings				</a>
			</li>
					</ul>
		</div>
		</div>
		<div id='mw-mf-page-center'>
									<div id="mw-mf-header">
		<a title="Open main menu" href="Special:MobileMenu#mw-mf-page-left" id="mw-mf-main-menu-button">				<img alt="menu"
				src="http://bits.wikimedia.org/static-1.21wmf3/extensions/MobileFrontend/stylesheets/common/images/blank.gif">
		</a>			<form id="mw-mf-searchForm" action="http://en.m.wikipedia.org/w/index.php" class="search_bar" method="get">
			<input type="hidden" value="Special:Search" name="title" />
			<div id="mw-mf-sq" class="divclearable">
				<input type="search" name="search" id="mw-mf-search" size="22" value="" autocomplete="off" maxlength="1024" class="search"
					placeholder="Search Wikipedia"
					/>
				<img src="http://bits.wikimedia.org/static-1.21wmf3/extensions/MobileFrontend/stylesheets/common/images/blank.gif" alt="Clear" class="clearlink" id="mw-mf-clearsearch" title="Clear"/>
				<input class='searchSubmit' type="submit" value="Go">
			</div>
		</form>
	</div>
	<div id="results"></div>
		<div class='show ' id='content_wrapper'>
						<h1 id="firstHeading">Burroughs large systems</h1>			
<p>In the 1970s, <a href="http://en.m.wikipedia.org/wiki/Burroughs_Corporation" title="Burroughs Corporation">Burroughs Corporation</a> was organized into three divisions with very different product line architectures for high-end, mid-range, and entry-level business computer systems. Each division's product line grew from a different concept for how to optimize a computer's instruction set for particular programming languages. The <b>Burroughs Large Systems Group</b> designed large mainframes using <b>stack machine</b> instruction sets with dense instruction syllables<sup id="cite_ref-1" class="reference"><a href="Burroughs_large_systems#cite_note-1"><span>[</span>NB 1<span>]</span></a></sup> and 48-bit data words. The first such design was the B5000 in 1961. It was optimized for running <a href="http://en.m.wikipedia.org/wiki/ALGOL_60" title="ALGOL 60">ALGOL 60</a> extremely well, using simple compilers. It evolved into the B5500. Subsequent major redesigns include the B6500/B6700 line and its successors, and the separate B8500 line. 'Burroughs Large Systems' referred to all of these product lines together, in contrast to the <a href="http://en.m.wikipedia.org/wiki/COBOL" title="COBOL">COBOL</a>-optimized <a href="http://en.m.wikipedia.org/wiki/Burroughs_B2500" title="Burroughs B2500">Medium Systems</a> or the flexible-architecture <a href="http://en.m.wikipedia.org/wiki/B1700" title="B1700" class="mw-redirect">Small Systems</a>.</p>
<p>Founded in the 1880s, Burroughs was the oldest continuously operating entity in computing, but by the late 1950s its computing equipment was still limited to electromechanical <a href="http://en.m.wikipedia.org/wiki/Accounting_Machine" title="Accounting Machine" class="mw-redirect">accounting machines</a> such as the <a href="http://en.m.wikipedia.org/wiki/Burroughs_Sensimatic" title="Burroughs Sensimatic" class="mw-redirect">Sensimatic</a>; as such it had nothing to compete with its traditional rivals <a href="http://en.m.wikipedia.org/wiki/IBM" title="IBM">IBM</a> and <a href="http://en.m.wikipedia.org/wiki/NCR_Corporation" title="NCR Corporation">NCR</a> who had started to produce larger-scale computers, or with recently-founded <a href="http://en.m.wikipedia.org/wiki/Univac" title="Univac" class="mw-redirect">Univac</a>. While in 1956 it branded as the B205 a machine produced by a company it bought, its first internally developed machine, the B5000, was designed in 1961 and Burroughs sought to address its late entry in the market with the strategy of a completely different design based on the most advanced computing ideas available at the time. While the B5000 architecture is dead, it inspired the B6500 (and subsequent B6700 &amp; B7700). Computers using that architecture are still in production as the <a href="http://en.m.wikipedia.org/wiki/Unisys" title="Unisys">Unisys</a> ClearPath Libra servers which run an evolved but compatible version of the <a href="http://en.m.wikipedia.org/wiki/Burroughs_MCP" title="Burroughs MCP">MCP</a> operating system first introduced with the B6700. The third and largest line, the B8500,<sup id="cite_ref-Da8500_2-0" class="reference"><a href="Burroughs_large_systems#cite_note-Da8500-2"><span>[</span>1<span>]</span></a></sup><sup id="cite_ref-burroughs3g_3-0" class="reference"><a href="Burroughs_large_systems#cite_note-burroughs3g-3"><span>[</span>2<span>]</span></a></sup> had no commercial success. In addition to a proprietary <a href="http://en.m.wikipedia.org/wiki/CMOS" title="CMOS">CMOS</a> processor design Unisys also uses Intel <a href="http://en.m.wikipedia.org/wiki/Xeon" title="Xeon">Xeon</a> processors and runs <a href="http://en.m.wikipedia.org/wiki/Burroughs_MCP" title="Burroughs MCP">MCP</a>, <a href="http://en.m.wikipedia.org/wiki/Microsoft_Windows" title="Microsoft Windows">Microsoft Windows</a> and <a href="http://en.m.wikipedia.org/wiki/Linux" title="Linux">Linux</a> operating systems on their Libra servers.</p>
<div class="thumb tright">
<div class="thumbinner" style="width:422px;">
<a href="http://en.m.wikipedia.org/wiki/File:B6700.jpg" class="image"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/9/98/B6700.jpg/420px-B6700.jpg" width="420" height="494" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/98/B6700.jpg/630px-B6700.jpg 1.5x, //upload.wikimedia.org/wikipedia/en/9/98/B6700.jpg 2x"></a>
<div class="thumbcaption">

Figure 4.5 From the ACM Monograph in the References. <i><a href="http://en.m.wikipedia.org/wiki/Elliot_Organick" title="Elliot Organick" class="mw-redirect">Elliot Organick</a> 1973.</i>
</div>
</div>
</div>
<h2> <span class="mw-headline" id="B5000">B5000</span>
</h2>
<p>The first member of the first series, the B5000,<sup id="cite_ref-B5000-21005_4-0" class="reference"><a href="Burroughs_large_systems#cite_note-B5000-21005-4"><span>[</span>3<span>]</span></a></sup> was designed beginning in 1961 by a team under the leadership of <a href="http://en.m.wikipedia.org/wiki/Robert_(Bob)_Barton" title="Robert (Bob) Barton" class="mw-redirect">Robert (Bob) Barton</a>. It was a unique machine, well ahead of its time. It has been listed by the influential computing scientist <a href="http://en.m.wikipedia.org/wiki/John_Mashey" title="John Mashey">John Mashey</a> as one of the architectures that he admires the most. "I always thought it was one of the most innovative examples of combined hardware/software design I've seen, and far ahead of its time."<sup id="cite_ref-johnmashey_5-0" class="reference"><a href="Burroughs_large_systems#cite_note-johnmashey-5"><span>[</span>4<span>]</span></a></sup> The B5000 was succeeded by the B5500<sup id="cite_ref-B1021326_6-0" class="reference"><a href="Burroughs_large_systems#cite_note-B1021326-6"><span>[</span>5<span>]</span></a></sup> and B5700. While there was no successor to the B5700, the B5000 line heavily influenced the design of the B6500, and Burroughs ported the <a href="http://en.m.wikipedia.org/wiki/Burroughs_MCP" title="Burroughs MCP">Master Control Program</a> (<b>MCP</b>) to that machine.</p>
<h3> <span class="mw-headline" id="Unique_features">Unique features</span>
</h3>
<ul>
<li>All code automatically <a href="http://en.m.wikipedia.org/wiki/Reentrant_(subroutine)" title="Reentrant (subroutine)" class="mw-redirect">reentrant</a> (fig 4.5 from the ACM Monograph shows <a href="http://en.m.wikipedia.org/wiki/Zero_address_arithmetic" title="Zero address arithmetic">in a nutshell</a> why): programmers don't have to do anything more to have any code in any language spread across processors than to use just the two shown simple primitives. This is perhaps the canonical but no means the only benefit of these major distinguishing features of this architecture:
<ul>
<li>Partially data-driven <a href="http://en.m.wikipedia.org/wiki/Tagged_architecture" title="Tagged architecture">tagged</a> and descriptor-based architecture</li>
<li>Hardware was designed to support software requirements</li>
<li>Hardware designed to exclusively support <a href="http://en.m.wikipedia.org/wiki/High-level_programming_language" title="High-level programming language">high-level</a> <a href="http://en.m.wikipedia.org/wiki/Programming_languages" title="Programming languages" class="mw-redirect">programming languages</a>
</li>
<li>No <a href="Assembly_language" title="Assembly language">Assembly language</a> or assembler; all system software written in an extended variety of <a href="http://en.m.wikipedia.org/wiki/ALGOL_60" title="ALGOL 60">ALGOL 60</a>. However, <a href="http://en.m.wikipedia.org/wiki/Executive_Systems_Problem_Oriented_Language" title="Executive Systems Problem Oriented Language">ESPOL</a> had statements for each of the syllables in the architecture.</li>
<li>Few programmer accessible registers</li>
<li>Simplified <a href="http://en.m.wikipedia.org/wiki/Instruction_set" title="Instruction set">instruction set</a>
</li>
<li>Stack architecture (to support high-level algorithmic languages)</li>
<li>Support for high-level <a href="Operating_system" title="Operating system">operating system</a> (MCP, <a href="MCP_(Burroughs_Large_Systems)" title="MCP (Burroughs Large Systems)" class="mw-redirect">Master Control Program</a>)</li>
</ul>
</li>
</ul>
<ul>
<li>Support for master/slave multiprocessing</li>
<li>Support for other languages such as <a href="http://en.m.wikipedia.org/wiki/COBOL" title="COBOL">COBOL</a>
</li>
<li>Powerful string manipulation</li>
<li>An attempt at a secure architecture prohibiting unauthorized access of data or disruptions to operations<sup id="cite_ref-7" class="reference"><a href="Burroughs_large_systems#cite_note-7"><span>[</span>NB 2<span>]</span></a></sup>
</li>
<li>Early error-detection supporting development and testing of software</li>
<li>First commercial implementation of virtual memory<sup id="cite_ref-8" class="reference"><a href="Burroughs_large_systems#cite_note-8"><span>[</span>NB 3<span>]</span></a></sup>
</li>
<li>Successors still exist in the <a href="http://en.m.wikipedia.org/wiki/Unisys" title="Unisys">Unisys</a> ClearPath/MCP machines</li>
<li>Influenced many of today's computing techniques</li>
</ul>
<table class="metadata plainlinks ambox ambox-notice" style=""><tr>
<td class="mbox-image">
<div style="width: 52px;"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/c/c8/Ambox_notice.png" width="40" height="40"></div>
</td>
<td class="mbox-text" style=""><span class="mbox-text-span">In the following discussion, the machine designations, B5000, A Series, and ClearPath/MCP are used interchangeably although this needlessly conflates the features and concepts of the various machines and should be edited someday to keep clear the distinctions between the 5000/5500/5700 and 6500 et seq, and A Series. </span></td>
</tr></table>
<h4> <span class="mw-headline" id="Unique_system_design">Unique system design</span>
</h4>
<p>The B5000 was revolutionary at the time in that the architecture and instruction set were designed with the needs of software taken into consideration. This was a large departure from the computer system design of the time, where a processor and its instruction set would be designed and then handed over to the software people, and is still. That is, modern architectures such as <a href="http://en.m.wikipedia.org/wiki/X86_architecture" title="X86 architecture" class="mw-redirect">x86</a> or <a href="http://en.m.wikipedia.org/wiki/PowerPC" title="PowerPC">PPC</a> are essentially traditional instruction set based architectures rather than holistic designs like the original Burroughs systems.</p>
<h4> <span class="mw-headline" id="Language_support">Language support</span>
</h4>
<p>The B5000 was designed to exclusively support high-level languages. This was at a time when such languages were just coming to prominence with <a href="FORTRAN" title="FORTRAN" class="mw-redirect">FORTRAN</a> and then <a href="http://en.m.wikipedia.org/wiki/COBOL" title="COBOL">COBOL</a>. FORTRAN and COBOL were considered weaker languages by some, when it comes to modern software techniques, so a newer, mostly untried language was adopted, <a href="http://en.m.wikipedia.org/wiki/Algol_60" title="Algol 60" class="mw-redirect">ALGOL-60</a>. The ALGOL dialect chosen for the B5000 was <a href="http://en.m.wikipedia.org/wiki/Elliott_ALGOL" title="Elliott ALGOL">Elliott ALGOL</a>, first designed and implemented by <a href="http://en.m.wikipedia.org/wiki/C._A._R._Hoare" title="C. A. R. Hoare" class="mw-redirect">C.A.R. Hoare</a> on an <span class="new" title="Elliott 503 (page does not exist)">Elliott 503</span>. This was a practical extension of ALGOL with IO instructions (which ALGOL had ignored) and powerful string processing instructions. Hoare's famous <a href="http://en.m.wikipedia.org/wiki/Turing_Award" title="Turing Award">Turing Award</a> lecture was on this subject.</p>
<p>Thus the B5000 was based on a very powerful language. Most other vendors could only dream of implementing an ALGOL compiler and most in the industry dismissed ALGOL as being unimplementable. However, a bright young student named <a href="http://en.m.wikipedia.org/wiki/Donald_Knuth" title="Donald Knuth">Donald Knuth</a> had previously implemented <a href="http://en.m.wikipedia.org/wiki/ALGOL_58" title="ALGOL 58">ALGOL 58</a> on an earlier Burroughs machine during the three months of his summer break. Many wrote ALGOL off, mistakenly believing that high-level languages could not have the same power as assembler, and thus not realizing ALGOL's potential as a systems programming language.</p>
<p>The Burroughs ALGOL compiler was very fast — this impressed the Dutch scientist <a href="http://en.m.wikipedia.org/wiki/Edsger_Dijkstra" title="Edsger Dijkstra" class="mw-redirect">Edsger Dijkstra</a> when he submitted a program to be compiled at the B5000 Pasadena plant. His deck of cards was compiled almost immediately and he immediately wanted several machines for his university, <a href="http://en.m.wikipedia.org/wiki/Eindhoven_University_of_Technology" title="Eindhoven University of Technology">Eindhoven University of Technology</a> in the Netherlands. The compiler was fast for several reasons, but the primary reason was that it was a <a href="http://en.m.wikipedia.org/wiki/One-pass_compiler" title="One-pass compiler">one-pass compiler</a>. Early computers did not have enough memory to store the source code, so compilers (and even assemblers) usually needed to read the source code more than once. The Burroughs ALGOL syntax, unlike the official language, requires that each variable (or other object) be declared before it is used, so it is feasible to write an ALGOL compiler that reads the data only once. This concept has profound theoretical implications, but it also permits very fast compiling. Burroughs large systems could compile as fast as they could read the source code from the <a href="http://en.m.wikipedia.org/wiki/Punched_card" title="Punched card">punched cards</a>, and they had the fastest card readers in the industry.</p>
<p>The powerful Burroughs COBOL compiler was also a one-pass compiler and equally fast. A 4000-card COBOL program compiled as fast as the 1000-card/minute readers could read the code. The program was ready to use as soon as the cards went through the reader.</p>
<h2> <span class="mw-headline" id="B6500">B6500</span>
</h2>
<p>The B6500 and B7500 were the first computers in the only Burroughs system to survive to the present day. While they were inspired by the B5000, they had a totally new architecture. Among the most important differences were</p>
<ul>
<li>The B6500 had variable length instructions with an 8-bit syllable instead of fixed length instructions with a 12-bit syllable.</li>
<li>The B6500 had a 51-bit<sup id="cite_ref-9" class="reference"><a href="Burroughs_large_systems#cite_note-9"><span>[</span>NB 4<span>]</span></a></sup> instead of a 48-bit word, and used 3 bits as a <a href="http://en.m.wikipedia.org/wiki/Tagged_architecture" title="Tagged architecture">tag</a>
</li>
<li>The B6500 had <a href="http://en.m.wikipedia.org/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">Symmetric Multiprocessing (SMP)</a>
</li>
<li>The B6500 had a <a href="http://en.m.wikipedia.org/wiki/Spaghetti_stack" title="Spaghetti stack">Saguaro stack</a>
</li>
<li>The B6500 had paged arrays</li>
<li>The B6500 had a <i>Display</i> to allow nested subroutines to access variables in outer blocks.</li>
</ul>
<h2> <span class="mw-headline" id="B8500">B8500</span>
</h2>
<p>The B8500<sup id="cite_ref-Da8500_2-1" class="reference"><a href="Burroughs_large_systems#cite_note-Da8500-2"><span>[</span>1<span>]</span></a></sup><sup id="cite_ref-burroughs3g_3-1" class="reference"><a href="Burroughs_large_systems#cite_note-burroughs3g-3"><span>[</span>2<span>]</span></a></sup> line derives from the D825,<sup id="cite_ref-10" class="reference"><a href="Burroughs_large_systems#cite_note-10"><span>[</span>6<span>]</span></a></sup> a military computer that was inspired by the B5000.</p>
<p>The B8500, designed in the 1960s, was an attempt to merge the B5500 and the D825 designs. The system used monolithic integrated circuits with magnetic thin-film memory. The architecture employed a 48-bit word, stack, and descriptors like the B5500, but was not advertised as being upward-compatible.<sup id="cite_ref-Da8500_2-2" class="reference"><a href="Burroughs_large_systems#cite_note-Da8500-2"><span>[</span>1<span>]</span></a></sup> The B8500 could never be gotten to work reliably, and the project was canceled after 1970, never having delivered a completed system.<sup id="cite_ref-burroughs3g_3-2" class="reference"><a href="Burroughs_large_systems#cite_note-burroughs3g-3"><span>[</span>2<span>]</span></a></sup></p>
<h2> <span class="mw-headline" id="History">History</span>
</h2>
<table class="metadata plainlinks ambox mbox-small-left ambox-content" style=""><tr>
<td class="mbox-image"><a href="http://en.m.wikipedia.org/wiki/File:Wiki_letter_w_cropped.svg" class="image"><img alt="[icon]" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/20px-Wiki_letter_w_cropped.svg.png" width="20" height="14" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/30px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png 2x"></a></td>
<td class="mbox-text" style=""><span class="mbox-text-span">This section requires <a class="external text" href="http://en.wikipedia.org/w/index.php?title=Burroughs_large_systems&amp;action=edit">expansion</a>. <small><i>(June 2008)</i></small></span></td>
</tr></table>
<table class="metadata plainlinks ambox ambox-notice" style=""><tr>
<td class="mbox-image">
<div style="width: 52px;"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/c/c8/Ambox_notice.png" width="40" height="40"></div>
</td>
<td class="mbox-text" style=""><span class="mbox-text-span">In the following discussion, the machine designations, B5000, A Series, and ClearPath/MCP are used interchangeably although this needlessly conflates the features and concepts of the various machines and should be edited someday to keep clear the distinctions between the 5000/5500/5700 and 6500 et seq, and A Series. </span></td>
</tr></table>
<p>The first of the Burroughs large systems was the B5000. Designed in 1961, it was a second-generation computer using <a href="http://en.m.wikipedia.org/wiki/Discrete_device" title="Discrete device" class="mw-redirect">discrete transistor</a> logic and <a href="http://en.m.wikipedia.org/wiki/Magnetic_core_memory" title="Magnetic core memory" class="mw-redirect">magnetic core memory</a>. The successor machines followed the hardware development trends to re-implement the architecture in new logic over the next 25 years, with the B5500, B6500, B5700, B6700, B7700, B6800, B7800, and finally the Burroughs A series. After a merger in which Burroughs acquired <a href="http://en.m.wikipedia.org/wiki/Sperry_Corporation" title="Sperry Corporation">Sperry Corporation</a> and changed its name to <a href="http://en.m.wikipedia.org/wiki/Unisys" title="Unisys">Unisys</a>, the company continued to develop new machines based on the <b>MCP <a href="http://en.m.wikipedia.org/wiki/CMOS" title="CMOS">CMOS</a></b> <a href="http://en.m.wikipedia.org/wiki/ASIC" title="ASIC" class="mw-redirect">ASIC</a>. These machines were the Libra 100 through the Libra 500, With the Libra 590 being announced in 2005. Later Libras, including the 590, also incorporate Intel Xeon processors and can run the Burroughs large systems architecture in emulation as well as on the MCP CMOS processors. It is unclear if Unisys will continue development of new MCP CMOS ASICs.</p>
<table class="wikitable" cellpadding="0" cellspacing="0" style="margin-left: auto; margin-right: auto; width: 600px;">
<tr>
<th style="background: #017A5B;" colspan="4"><span style="color:white">Burroughs (1961–1986)</span></th>
</tr>
<tr>
<td><b>B5000</b></td>
<td>1961</td>
<td>initial system, 2nd generation (transistor) computer</td>
</tr>
<tr>
<td><b>B5500</b></td>
<td>1964</td>
<td>3x speed improvement(?)<sup id="cite_ref-burroughs3g_3-3" class="reference"><a href="Burroughs_large_systems#cite_note-burroughs3g-3"><span>[</span>2<span>]</span></a></sup>
</td>
</tr>
<tr>
<td><b>B6500</b></td>
<td>1969</td>
<td>3rd gen computer (integrated circuits), up to 4 processors</td>
</tr>
<tr>
<td><b>B5700</b></td>
<td>1971</td>
<td>new name for B5500<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Disputed_statement" title="Wikipedia:Disputed statement"><span title="This claim has reliable sources with contradicting facts from November 2010">disputed</span></a> <span class="metadata">– <a href="http://en.m.wikipedia.org/wiki/Talk:Burroughs_large_systems#Talk:Burroughs_large_systems.23_Are_x700_new_names_for_old_products_or_names_for_new_products" title="Talk:Burroughs large systems">discuss</a></span></i>]</sup>
</td>
</tr>
<tr>
<td><b>B6700</b></td>
<td>1971</td>
<td>new name/bug fix for B6500<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Disputed_statement" title="Wikipedia:Disputed statement"><span title="This claim has reliable sources with contradicting facts from November 2010">disputed</span></a> <span class="metadata">– <a href="http://en.m.wikipedia.org/wiki/Talk:Burroughs_large_systems#Talk:Burroughs_large_systems.23_Are_x700_new_names_for_old_products_or_names_for_new_products" title="Talk:Burroughs large systems">discuss</a></span></i>]</sup>
</td>
</tr>
<tr>
<td><b>B7700</b></td>
<td>1972</td>
<td>faster processor, cache for stack, up to 8 requestors (IO or Central processors) in one or two partitions.</td>
</tr>
<tr>
<td><b>B6800</b></td>
<td>1977?</td>
<td>semiconductor memory, <a href="http://en.m.wikipedia.org/wiki/Non-Uniform_Memory_Access" title="Non-Uniform Memory Access">NUMA</a> architecture</td>
</tr>
<tr>
<td><b>B7800</b></td>
<td>1977?</td>
<td>semiconductor memory, faster, up to 8 requestors (IO or Central processors) in one or two partitions.</td>
</tr>
<tr>
<td><b>B5900</b></td>
<td>1980?</td>
<td>semiconductor memory, <a href="http://en.m.wikipedia.org/wiki/Non-Uniform_Memory_Access" title="Non-Uniform Memory Access">NUMA</a> architecture. Max of 4 B5900 CPUs bound to a local memory and a common Global Memory II (tm)</td>
</tr>
<tr>
<td><b>B6900</b></td>
<td>1979?</td>
<td>semiconductor memory, <a href="http://en.m.wikipedia.org/wiki/Non-Uniform_Memory_Access" title="Non-Uniform Memory Access">NUMA</a> architecture. Max of 4 B6900 CPUs bound to a local memory and a common Global Memory(tm)</td>
</tr>
<tr>
<td><b>B7900</b></td>
<td>1982?</td>
<td>semiconductor memory, faster, code &amp; data caches, <a href="http://en.m.wikipedia.org/wiki/Non-Uniform_Memory_Access" title="Non-Uniform Memory Access">NUMA</a> architecture,
<p>1-2 HDUs (IO), 1-2 APs, 1-4 CPUs, Soft implementation of NUMA memory allowed CPUs to float from memory space to memory space.</p>
</td>
</tr>
<tr>
<td><b>A9/A10</b></td>
<td>1984</td>
<td>B6000 class, First piplined processor in the mid-range, single CPU (dual on A10), First to support eMode Beta (expanded Memory Addressing)</td>
</tr>
<tr>
<td><b>A12/A15</b></td>
<td>1985</td>
<td>B7000 class, Re-implemented in custom-designed Motorola <a href="http://en.m.wikipedia.org/wiki/Emitter-coupled_logic" title="Emitter-coupled logic">ECL</a> MCA1, then MCA2 <a href="http://en.m.wikipedia.org/wiki/Gate_array" title="Gate array">gate arrays</a>, single CPU single HDU (A12) 1-4 CPU, 1-2 HDU (A15)</td>
</tr>
<tr>
<th style="background: #017A5B;" colspan="4"><span style="color:white">Unisys (1986–present))</span></th>
</tr>
<tr>
<td><b>Micro A</b></td>
<td>1989</td>
<td>desktop "mainframe" with single-chip SCAMP<sup id="cite_ref-11" class="reference"><a href="Burroughs_large_systems#cite_note-11"><span>[</span>7<span>]</span></a></sup><sup id="cite_ref-12" class="reference"><a href="Burroughs_large_systems#cite_note-12"><span>[</span>8<span>]</span></a></sup> processor.</td>
</tr>
<tr>
<td><b>Clearpath HMP NX 4000</b></td>
<td>198?</td>
<td> ??</td>
</tr>
<tr>
<td><b>Clearpath HMP NX 5000</b></td>
<td>199?</td>
<td> ??</td>
</tr>
<tr>
<td><b>Clearpath HMP LX 5000</b></td>
<td>1998</td>
<td>Implements Burroughs Large systems in emulation only (<a href="http://en.m.wikipedia.org/wiki/Xeon" title="Xeon">Xeon</a> processors)<sup id="cite_ref-13" class="reference"><a href="Burroughs_large_systems#cite_note-13"><span>[</span>9<span>]</span></a></sup>
</td>
</tr>
<tr>
<td><b>Libra 100</b></td>
<td>2002?</td>
<td> ??</td>
</tr>
<tr>
<td><b>Libra 200</b></td>
<td>200?</td>
<td> ??</td>
</tr>
<tr>
<td><b>Libra 300</b></td>
<td>200?</td>
<td> ??</td>
</tr>
<tr>
<td><b>Libra 400</b></td>
<td>200?</td>
<td> ??</td>
</tr>
<tr>
<td><b>Libra 500</b></td>
<td>2005?</td>
<td>e.g. Libra 595<sup id="cite_ref-14" class="reference"><a href="Burroughs_large_systems#cite_note-14"><span>[</span>10<span>]</span></a></sup>
</td>
</tr>
<tr>
<td><b>Libra 600</b></td>
<td>2006?</td>
<td> ??</td>
</tr>
</table>
<h2> <span class="mw-headline" id="Primary_lines_of_hardware">Primary lines of hardware</span>
</h2>
<p>Hardware and software design, development, and manufacturing were split between two primary locations, in <a href="http://en.m.wikipedia.org/wiki/Orange_County,_California" title="Orange County, California">Orange County, California</a>, and the outskirts of <a href="http://en.m.wikipedia.org/wiki/Philadelphia" title="Philadelphia">Philadelphia</a>. The Orange County location, which centered around a plant in <a href="http://en.m.wikipedia.org/wiki/Mission_Viejo,_California" title="Mission Viejo, California">Mission Viejo, California</a> but at times included facilities in nearby <a href="http://en.m.wikipedia.org/wiki/Irvine,_California" title="Irvine, California">Irvine</a> and <a href="http://en.m.wikipedia.org/wiki/Lake_Forest,_California" title="Lake Forest, California">Lake Forest</a>, was responsible for the smaller B6x00 line, while the East Coast operations, centered around <a href="http://en.m.wikipedia.org/wiki/Tredyffrin,_Pennsylvania" title="Tredyffrin, Pennsylvania" class="mw-redirect">Tredyffrin, Pennsylvania</a>, handled the larger B7x00 line. All machines from both lines were fully object-compatible, meaning a program compiled on one could be executed on another. Newer and larger models had instructions which were not supported on older and slower models, but the hardware, when encountering an unrecognized instruction, invoked an operating system function which interpreted it. Other differences include how process switching and I/O were handled, and maintenance and cold-starting functionality. Larger systems included hardware process scheduling and more capable input/output modules, and more highly-functional maintenance processors. When the Bxx00 models were replaced by the A Series models, the differences were retained but no longer readily identifiable by model number.</p>
<h2> <span class="mw-headline" id="ALGOL">ALGOL</span>
</h2>
<div class="rellink relarticle mainarticle">Main article: <a href="ALGOL" title="ALGOL">ALGOL</a>
</div>
<p>The Burroughs large systems implement an ALGOL-derived <a href="http://en.m.wikipedia.org/wiki/Stack_architecture" title="Stack architecture" class="mw-redirect">stack architecture</a>, unlike linear architectures such as <a href="PDP-11" title="PDP-11">PDP-11</a>, <a href="http://en.m.wikipedia.org/wiki/68k" title="68k" class="mw-redirect">Motorola M68k</a>, and <a href="http://en.m.wikipedia.org/wiki/Itanium" title="Itanium">Itanium</a> or segmented architectures such as <a href="http://en.m.wikipedia.org/wiki/X86" title="X86">x86</a> and <a href="http://en.m.wikipedia.org/wiki/Texas_Instruments" title="Texas Instruments">Texas Instruments</a>. (This refers to the layout of the memory and how a program uses it.)</p>
<p>While B5000 was designed specifically around ALGOL, this was only a starting point. Other business-oriented languages such as COBOL were also well supported, most notably by the powerful string operators which were included for the development of fast compilers.</p>
<p>The ALGOL used on the B5000 is an extended ALGOL subset. It includes powerful string manipulation instructions but excludes certain ALGOL constructs, notably unspecified formal parameters. A DEFINE mechanism serves a similar purpose to the <a href="C_preprocessor" title="C preprocessor">#defines</a> found in C, but is fully integrated into the language rather than being a preprocessor. The EVENT data type facilitates coordination between processes, and ON FAULT blocks enable handling program faults.</p>
<p>The user level of ALGOL does not include many of the insecure constructs needed by the operating system and other system software. Two levels of language extensions provide the additional constructs: ESPOL and NEWP for writing the MCP and closely related software, and DCALGOL and DMALGOL to provide more specific extensions for specific kinds of system software.</p>
<h3> <span class="mw-headline" id="ESPOL_and_NEWP">ESPOL and NEWP</span>
</h3>
<p>Originally, the B5000 MCP operating system was written in an extension of extended ALGOL called ESPOL (Executive Systems Programming Oriented Language). This was replaced in the mid-to-late 70s by a language called NEWP. Though NEWP probably just meant "New Programming language", legends surround the name. A common (perhaps apocryphal) story around Burroughs at the time suggested it came from “<i>No Executive Washroom Privileges</i>.” Another story is that circa 1976, John McClintock of Burroughs (the software engineer developing NEWP) named the language "NEWP" after being asked, yet again, "does it have a name yet": answering "nyoooop", he adopted that as a name. NEWP, too, was a subset ALGOL extension, but it was more secure than ESPOL, and dropped some little-used complexities of ALGOL. In fact, all unsafe constructs are rejected by the NEWP compiler unless a block is specifically marked to allow those instructions. Such marking of blocks provide a multi-level protection mechanism.</p>
<p>NEWP programs that contain unsafe constructs are initially non-executable. The security administrator of a system is able to "bless" such programs and make them executable, but normal users are not able to do this. (Even "privileged users", who normally have essentially root privilege, may be unable to do this depending on the configuration chosen by the site.) While NEWP can be used to write general programs and has a number of features designed for large software projects, it does not support everything ALGOL does.</p>
<p>NEWP has a number of facilities to enable large-scale software projects, such as the operating system, including named interfaces (functions and data), groups of interfaces, modules, and super-modules. Modules group data and functions together, allowing easy access to the data as global within the module. Interfaces allow a module to import and export functions and data. Super-modules allow modules to be grouped.</p>
<h3> <span class="mw-headline" id="DCALGOL_and_Message_Control_Systems_.28MCS.29">DCALGOL and Message Control Systems (MCS)</span>
</h3>
<p>The second intermediate level of security between operating system code (in NEWP) and user programs (in ALGOL) is for middleware programs, which are written in DCALGOL (data comms ALGOL). This is used for message reception and dispatching which remove messages from input queues and places them on queues for other processes in the system to handle. Middleware such as COMS (introduced around 1984) receive messages from around the network and dispatch these messages to specific handling processes or to an MCS (Message Control System) such as CANDE ("<b>C</b>ommand <b>AND E</b>dit," the program development environment).</p>
<p>MCSs are items of software worth noting – they control user sessions and provide keeping track of user state without having to run per-user processes since a single MCS stack can be shared by many users. Load balancing can also be achieved at the MCS level. For example saying that you want to handle 30 users per stack, in which case if you have 31 to 60 users, you have two stacks, 61 to 90 users, three stacks, etc. This gives B5000 machines a great performance advantage in a server since you don't need to start up another user process and thus create a new stack each time a user attaches to the system. Thus you can efficiently service users (whether they require state or not) with MCSs. MCSs also provide the backbone of large-scale transaction processing.</p>
<p>The MCS talked with an external co-processor, the TCP (Terminal Control Processor). This was a 24-bit minicomputer with a conventional register architecture and hardware I/O capability to handle thousands of remote terminals. The TCP and the B6500 communicated by messages in memory, essentially packets in today's terms, and the MCS did the B6500-side processing of those messages. The TCP did have an assembler, but that assembler was the B6500 ALGOL compiler. There was one ALGOL function for each kind of TCP instruction, and if you called that function then the corresponding TCP instruction bits would be emitted to the output. A TCP program was an ALGOL program comprising nothing but a long list of calls on these functions, one for each assembly language statement. Essentially ALGOL acted like the macro pass of a macro assembler. The first pass was the ALGOL compiler; the second pass was running the resulting program (on the B6500) which would then emit the binary for the TCP.</p>
<h3> <span class="mw-headline" id="DMALGOL_and_databases">DMALGOL and databases</span>
</h3>
<p>Another variant of ALGOL is DMALGOL (Data Management ALGOL). DMALGOL is ALGOL extended for compiling the DMSII database software from database description files created by the DASDL compiler. Database designers and administrators compile database descriptions to generate DMALGOL code tailored for the tables and indexes specified. Administrators never need to write DMALGOL themselves. Normal user-level programs obtain database access by using code written in application languages, mainly ALGOL and COBOL, extended with database instructions and transaction processing directives. The most notable feature of DMALGOL is its preprocessing mechanisms to generate code for handling tables and indices.</p>
<p>DMALGOL preprocessing includes variables and loops, and can generate names based on compile-time variables. This enables tailoring far beyond what can be done by preprocessing facilities which lack loops.</p>
<p>DMALGOL is used to provide tailored access routines for <a href="http://en.m.wikipedia.org/wiki/Unisys_DMSII" title="Unisys DMSII">DMSII</a> databases. After a database is defined using the Data Access and Structure Definition Language (DASDL), the schema is translated by the preprocessor into tailored DMALGOL access routines and then compiled. This means that, unlike in other DBMS implementations, there is often no need for database-specific if/then/else code at run-time. In the 1970s, this "tailoring" was used very extensively to reduce the code footprint and execution time. It became much less used in later years, partly because low-level fine tuning for memory and speed became less critical, and partly because eliminating the preprocessing made coding simpler and thus enabled more important optimizations.</p>
<p>Roy Guck of Burroughs was one of the main developers of <a href="http://en.m.wikipedia.org/wiki/Unisys_DMSII" title="Unisys DMSII">DMSII</a>.</p>
<p>In later years, with compiler code size being less of a concern, most of the preprocessing constructs were made available in the user level of ALGOL. Only the unsafe constructs and the direct processing of the database description file remain restricted to DMALGOL.</p>
<h2> <span class="mw-headline" id="Stack_architecture">Stack architecture</span>
</h2>
<p>In many early systems and languages, programmers were often told not to make their routines too small. Procedure calls and returns were expensive, because a number of operations had to be performed to maintain the stack. The B5000 was designed as a stack machine – all program data except for arrays (which include strings and objects) was kept on the stack. This meant that stack operations were optimized for efficiency. As a stack-oriented machine, there are no programmer addressable registers.</p>
<p><a href="http://en.m.wikipedia.org/wiki/Computer_multitasking" title="Computer multitasking">Multitasking</a> is also very efficient on B5000 machines. There is one specific instruction to perform process switches – MVST (move stack).<sup id="cite_ref-15" class="reference"><a href="Burroughs_large_systems#cite_note-15"><span>[</span>11<span>]</span></a></sup> Each stack represents a process (task or thread) and tasks can become blocked waiting on resource requests (which includes waiting for a processor to run on if the task has been interrupted because of preemptive multitasking). User programs cannot issue an MVST, and there is only one line of code in the operating system where this is done.</p>
<p>So a process switch proceeds something like this – a process requests a resource that is not immediately available, maybe a read of a record of a file from a block which is not currently in memory, or the system timer has triggered an interrupt. The operating system code is entered and run on top of the user stack. It turns off user process timers. The current process is placed in the appropriate queue for the resource being requested, or the ready queue waiting for the processor if this is a preemptive context switch. The operating system determines the first process in the ready queue and invokes the instruction move_stack, which makes the process at the head of the ready queue active.</p>
<h3> <span class="mw-headline" id="Stack_speed_and_performance">Stack speed and performance</span>
</h3>
<p>Some of the detractors of the B5000 architecture believed that stack architecture was inherently slow compared to register-based architectures. The trick to system speed is to keep data as close to the processor as possible. In the B5000 stack, this was done by assigning the top two positions of the stack to two registers A and B. Most operations are performed on those two top of stack positions. On faster machines past the B5000, more of the stack may be kept in registers or cache near the processor.</p>
<p>Thus the designers of the current successors to the B5000 systems can optimize in whatever is the latest technique, and programmers do not have to adjust their code for it to run faster – they do not even need to recompile, thus protecting software investment. Some programs have been known to run for years over many processor upgrades. Such speed up is limited on register-based machines.<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from January 2010">citation needed</span></a></i>]</sup></p>
<p>Another point for speed as promoted by the RISC designers was that processor speed is considerably faster if everything is on a single chip. It was a valid point in the 1970s when more complex architectures such as the B5000 required too many transistors to fit on a single chip. However, this is not the case today and every B5000 successor machine now fits on a single chip as well as the performance support techniques such as caches and instruction pipelines.</p>
<p>In fact, the A Series line of B5000 successors included the first single chip mainframe, the Micro-A of the late 1980s. This "mainframe" chip (named SCAMP for Single-Chip A-series Mainframe Processor) sat on an Intel-based plug-in PC board.</p>
<h3> <span class="mw-headline" id="How_programs_map_to_the_stack">How programs map to the stack</span>
</h3>
<p>Here is an example of how programs map to the stack structure</p>
<pre>
<b>begin</b>
   — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —
   — This is lexical level 2 (level zero is reserved for the operating system and level 1 for code segments).
   — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —
   
   — At level 2 we place global variables for our program.
   
   <b>integer</b> <i>i</i>, <i>j</i>, <i>k</i>;
   <b>real</b> <i>f</i>, <i>g</i>;
   <b>array</b> <i>a</i> [0:9];
   
   <b>procedure</b> <i>p</i> (<b>real</b> <i>p1</i>, <i>p2</i>);
      <b>value</b> <i>p1</i>;     — p1 passed by value, p2 implicitly passed by reference.
      <b>begin</b>
         — — — — — — — — — — — — — — — — — —
         — This block is at lexical level 3
         — — — — — — — — — — — — — — — — — —
         <b>real</b> <i>r1</i>, <i>r2</i>;<br><i>r2</i> := <i>p1</i> * <i>5</i>;
         <i>p2</i> := <i>r2</i>;  — This sets <i>g</i> to the value of <i>r2</i>
         <i>p1</i> := <i>r2</i>;  — This sets <i>p1</i> to <i>r2</i>, but not <i>f</i>
         — Since this overwrites the original value of <i>f</i> in <i>p1</i> it <i>might</i> be a
         — coding mistake.  Some few of ALGOL's successors therefore insist that
         — value parameters be read only – but most do not.
         
         <b>if</b> <i>r2</i> &gt; <i>10</i> <b>then</b>
            <b>begin</b>
               — — — — — — — — — — — — — — — — — — — — — — — — — — — —
               — A variable declared here makes this lexical level 4
               — — — — — — — — — — — — — — — — — — — — — — — — — — — —
               <b>integer</b> <i>n</i>;<br>               — The declaration of a variable makes this a block, which will invoke some
               — stack building code. Normally you won't declare variables here, in which
               — case this would be a compound statement, not a block.
               
               ... &lt;== sample stack is executing somewhere here.
            <b>end</b>;
      <b>end</b>;
      
   .....
   
   <i>p</i> (<i>f</i>, <i>g</i>);
<b>end</b>;
</pre>
<p>Each stack frame corresponds to a lexical level in the current execution environment. As you can see, lexical level is the static textual nesting of a program, not the dynamic call nesting. The visibility rules of ALGOL, a language designed for single pass compilers, mean that only variables declared before the current position are visible at that part of the code, thus the requirement for forward declarations. All variables declared in enclosing blocks are visible. Another case is that variables of the same name may be declared in inner blocks and these effectively hide the outer variables which become inaccessible.</p>
<p>Lexical nesting is static, unrelated to execution nesting with recursion, etc. so it is very rare to find a procedure nested more than five levels deep, and it could be argued that such programs would be poorly structured. B5000 machines allow nesting of up to 32 levels. This could cause difficulty for some systems that generated Algol source as output (tailored to solve some special problem) if the generation method frequently nested procedure within procedure.</p>
<h3> <span class="mw-headline" id="Procedures">Procedures</span>
</h3>
<p>Procedures can be invoked in four ways – normal, call, process, and run.</p>
<p>The normal invocation invokes a procedure in the normal way any language invokes a routine, by suspending the calling routine until the invoked procedure returns.</p>
<p>The <b>call</b> mechanism invokes a procedure as a coroutine. Coroutines have partner tasks, where control is explicitly passed between the tasks by means of a CONTINUE instruction. These are synchronous processes.</p>
<p>The <b>process</b> mechanism invokes a procedure as an asynchronous task and in this case a separate stack is set up starting at the lexical level of the processed procedure. As an asynchronous task, there is no control over exactly when control will be passed between the tasks, unlike coroutines. Note also that the processed procedure still has access to the enclosing environment and this is a very efficient IPC (Inter Process Communication) mechanism. Since two or more tasks now have access to common variables, the tasks must be synchronized to prevent race conditions, which is handled by the EVENT data type, where processes can WAIT on an event until they are caused by another cooperating process. EVENTs also allow for mutual exclusion synchronization through the PROCURE and LIBERATE functions. If for any reason the child task dies, the calling task can continue – however, if the parent process dies, then all child processes are automatically terminated. On a machine with more than one processor, the processes may run simultaneously. This EVENT mechanism is a basic enabler for multiprocessing in addition to multitasking.</p>
<h4> <span class="mw-headline" id="Run_invocation_type">Run invocation type</span>
</h4>
<p>The last invocation type is <b>run</b>. This runs a procedure as an independent task which can continue on after the originating process terminates. For this reason, the child process cannot access variables in the parent's environment, and all parameters passed to the invoked procedure must be call-by-value.</p>
<p>Thus Burroughs Extended ALGOL had some of the multi-processing and synchronization features of later languages like <a href="http://en.m.wikipedia.org/wiki/Ada_(programming_language)" title="Ada (programming language)">Ada</a>. It made use of the support for asynchronous processes that was built into the hardware.</p>
<h4> <span class="mw-headline" id="Inline_procedures">Inline procedures</span>
</h4>
<p>One last possibility is that a procedure may be declared INLINE, that is when the compiler sees a reference to it <a href="http://en.m.wikipedia.org/wiki/Inline_expansion" title="Inline expansion">the code for the procedure is generated inline</a> to save the overhead of a procedure call; this is best done for small pieces of code. Inline functions are similar to <a href="http://en.m.wikipedia.org/wiki/Parameterized_macro" title="Parameterized macro">parameterized macros</a> such as <a href="http://en.m.wikipedia.org/wiki/C_(programming_language)" title="C (programming language)">C</a> #defines, except you don't get the problems with parameters that you can with macros. This facility is available in NEWP.</p>
<h4> <span class="mw-headline" id="Asynchronous_calls">Asynchronous calls</span>
</h4>
<p>In the example program only normal calls are used, so all the information will be on a single stack. For asynchronous calls, the stack would be split into multiple stacks so that the processes share data but run asynchronously.</p>
<h4> <span class="mw-headline" id="Display_registers">Display registers</span>
</h4>
<p>A stack hardware optimization is the provision of D (or "display") registers. These are registers that point to the start of each called stack frame. These registers are updated automatically as procedures are entered and exited and are not accessible by any software. There are 32 D registers, which is what limits to 32 levels of lexical nesting.</p>
<p>Consider how we would access a lexical level 2 (D[2]) global variable from lexical level 5 (D[5]). Suppose the variable is 6 words away from the base of lexical level 2. It is thus represented by the address couple (2, 6). If we don't have D registers, we have to look at the control word at the base of the D[5] frame, which points to the frame containing the D[4] environment. We then look at the control word at the base of this environment to find the D[3] environment, and continue in this fashion until we have followed all the links back to the required lexical level. Note this is not the same path as the return path back through the procedures which have been called in order to get to this point. (The architecture keeps both the data stack and the call stack in the same structure, but uses control words to tell them apart.)</p>
<p>As you can see, this is quite inefficient just to access a variable. With D registers, the D[2] register points at the base of the lexical level 2 environment, and all we need to do to generate the address of the variable is to add its offset from the stack frame base to the frame base address in the D register. (There is an efficient linked list search operator LLLU, which could search the stack in the above fashion, but the D register approach is still going to be faster.) With D registers, access to entities in outer and global environments is just as efficient as local variable access.</p>
<pre>
D Tag Data                — Address couple, Comments
register        
</pre>
<pre>
| 0        | <i>n</i>          | (4, 1) The integer <i>n</i> (declared on entry to a block, not a procedure)
|-----------------------|
| D[4]==&gt;3 | <b>MSCW</b>       | (4, 0) The Mark Stack Control Word containing the link to D[3].
|=======================|
| 0        | <i>r2</i>         | (3, 5) The real <i>r2</i>
|-----------------------|
| 0        | <i>r1</i>         | (3, 4) The real <i>r1</i>
|-----------------------|
| 1        | <i>p2</i>         | (3, 3) A SIRW reference to <i>g</i> at (2,6)
|-----------------------|
| 0        | <i>p1</i>         | (3, 2) The parameter <i>p1</i> from value of <i>f</i> 
|-----------------------|
| 3        | <b>RCW</b>        | (3, 1) A return control word
|-----------------------|
| D[3]==&gt;3 | <b>MSCW</b>       | (3, 0) The Mark Stack Control Word containing the link to D[2].
|=======================|
| 1        | <i>a</i>          | (2, 7) The array <i>a</i>  ======&gt;[ten word memory block]
|-----------------------|
| 0        | <i>g</i>          | (2, 6) The real <i>g</i> 
|-----------------------|
| 0        | <i>f</i>          | (2, 5) The real <i>f</i> 
|-----------------------|
| 0        | <i>k</i>          | (2, 4) The integer <i>k</i> 
|-----------------------|
| 0        | <i>j</i>          | (2, 3) The integer <i>j</i> 
|-----------------------|
| 0        | <i>i</i>          | (2, 2) The integer <i>i</i>
|-----------------------|
| 3        | <b>RCW</b>        | (2, 1) A return control word
|-----------------------|
| D[2]==&gt;3 | <b>MSCW</b>       | (2, 0) The Mark Stack Control Word containing the link to the previous stack frame.
|=======================| — Stack bottom
</pre>
<p>If we had invoked the procedure p as a coroutine, or a process instruction, the D[3] environment would have become a separate D[3]-based stack. Note that this means that asynchronous processes still have access to the D[2] environment as implied in ALGOL program code. Taking this one step further, a totally different program could call another program’s code, creating a D[3] stack frame pointing to another process’ D[2] environment on top of its own process stack. At an instant the whole address space from the code’s execution environment changes, making the D[2] environment on the own process stack not directly addressable and instead make the D[2] environment in another process stack directly addressable. This is how library calls are implemented. At such a cross-stack call, the calling code and called code could even originate from programs written in different source languages and be compiled by different compilers.</p>
<p>Note that the D[1] and D[0] environments do not occur in the current process's stack. The D[1] environment is the code segment dictionary, which is shared by all processes running the same code. The D[0] environment represents entities exported by the operating system.</p>
<p>Stack frames actually don’t even have to exist in a process stack. This feature was used early on for file IO optimization, the FIB (file information block) was linked into the display registers at D[1] during IO operations. In the early nineties, this ability was implemented as a language feature as STRUCTURE BLOCKs and – combined with library technology - as CONNECTION BLOCKs. The ability to link a data structure into the display register address scope implemented object orientation. Thus, the B5000 actually used a form of object orientation long before the term was ever used.</p>
<p>On other systems, the compiler might build its symbol table in a similar manner, but eventually the storage requirements would be collated and the machine code would be written to use flat memory addresses of 16-bits or 32-bits or even 64-bits. These addresses might contain anything so that a write to the wrong address could damage anything. Instead, the two-part address scheme was implemented by the hardware. At each lexical level, variables were placed at displacements up from the base of the level's stack, typically occupying one word - double precision or complex variables would occupy two. Arrays were <i>not</i> stored in this area, only a one word descriptor for the array. Thus, at each lexical level the total storage requirement was not great: dozens, hundreds or a few thousand in extreme cases, certainly not a count requiring 32-bits or more. And indeed, this was reflected in the form of the VALC instruction (value call) that loaded an operand onto the stack. This op-code was two bits long and the rest of the byte's bits were concatenated with the following byte to give a fourteen-bit addressing field. The code being executed would be at some lexical level, say six: this meant that only lexical levels zero to six were valid, and so just three bits were needed to specify the lexical level desired. The address part of the VALC operation thus reserved just three bits for that purpose, with the remainder being available for referring to entities at that and lower levels. A deeply nested procedure (thus at a high lexical level) would have fewer bits available to identify entities, and so for level sixteen upwards their number was restricted. At the deepest nesting five bits would be needed to specify the choice of levels 0-31 thus leaving nine bits to identify 512 entities - not a severe constraint. This is much more compact than addressing entities by their literal memory address in a 32-bit addressing space. Further, only the VALC opcode loaded data: opcodes for ADD, MULT and so forth did no addressing, working entirely on the top elements of the stack.</p>
<p>Much more important is that this method meant that many errors available to systems employing flat addressing could not occur because they were simply unspeakable even at the machine code level. A task had no way to corrupt memory in use by another task, because it had no way to develop its address. Similarly, within a task, an array descriptor contained information on the array's bounds, and so any indexing operation was checked by the hardware: put another way, each array formed its own address space. In any case, the tagging of all memory words provided a second level of protection: a misdirected assignment of a value could only go to a data-holding location, not to one holding a pointer or an array descriptor, etc. and certainly not to a location holding machine code.</p>
<h4> <span class="mw-headline" id="Array_storage">Array storage</span>
</h4>
<p>Arrays were not stored contiguous in memory with other variables, they were each granted their own address space, which was located via the descriptor. The access mechanism was to calculate on the stack the index variable (which therefore had the full integer range potential, not just fourteen bits) and use it as the offset into the array's address space, with bound checking provided by the hardware. Should an array's length exceed 1,024 words, the array would be segmented, and the index be converted into a segment index and an offset into the indexed segment. In ALGOL's case, a multidimensional array would employ multiple levels of such addressing. For a reference to A(i,j), the first index would be into an array of descriptors, one descriptor for each of the rows of A, which row would then be indexed with j as for a single-dimensional array, and so on for higher dimensions. Hardware checking against the known bounds of all the array's indices would prevent erroneous indexing.</p>
<p>FORTRAN however regards all multidimensional arrays as being equivalent to a single-dimensional array of the same size, and for a multidimensional array simple integer arithmetic is used to calculate the offset where element A(i,j,k) would be found in that single sequence. The single-dimensional equivalent array, possibly segmented if large enough, would then be accessed in the same manner as a single-dimensional array in ALGOL. Although accessing outside this array would be prevented, a wrong value for one index combined with a suitably wrong value for another index might not result in a bounds violation of the single sequence array; in other words, the indices were not checked individually.</p>
<p>Because an array's storage was not bounded on each side by storage for other items, it was easy for the system to "resize" an array - though changing the number of dimensions was precluded because compilers required all references to have the same number of dimensions. In ALGOL's case, this enabled the development of "ragged" arrays, rather than the usual fixed rectangular (or higher dimension) arrays. Thus in two dimensions, a ragged array would have rows that were of different sizes. For instance, given a large array A(100,100) of mostly-zero values, a sparse array representation that was declared as SA(100,0) could have each row resized to have exactly enough elements to hold only the non-zero values of A along that row.</p>
<p>Because arrays larger than 1024 words were segmented but smaller arrays were not, on a system that was short of real memory, increasing the declared size of a collection of scratchpad arrays from 1,000 to say 1,050 could mean that the program would run with far less "thrashing" as only the smaller individual segments in use were needed in memory. Actual storage for an array segment would be allocated at run time only if an element in that segment were accessed, and all elements of a created segment would be initialised to zero. Not initialising an array to zero at the start therefore was encouraged by this, normally an unwise omission.</p>
<h3> <span class="mw-headline" id="Stack_structure_advantages">Stack structure advantages</span>
</h3>
<p>One nice thing about the stack structure is that if a program does happen to fail, a stack dump is taken and it is very easy for a programmer to find out exactly what the state of a running program was. Compare that to core dumps and exchange packages of other systems.</p>
<p>Another thing about the stack structure is that programs are implicitly recursive. FORTRAN was not a recursive language and perhaps one stumbling block to people's understanding of how ALGOL was to be implemented was how to implement recursion. On the B5000, this was not a problem – in fact, they had the reverse problem, how to stop programs from being recursive. In the end they didn't bother, even the Burroughs FORTRAN compiler was recursive, since it was unproductive to stop it being so. This could have odd effects, as with a system for the formal manipulation of mathematical expressions whose central subroutines repeatedly invoked each other without ever returning: large jobs were ended by stack overflow!</p>
<p>Thus Burroughs FORTRAN was better than any other implementation of FORTRAN.<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from February 2007">citation needed</span></a></i>]</sup> For instance, for subroutines and functions it checked that they were invoked with the correct number of parameters, as is normal for ALGOL-style compilers. On other computers, such mismatches were common causes of crashes. In fact, Burroughs became known for its superior compilers and implementation of languages, including the object-oriented <a href="http://en.m.wikipedia.org/wiki/Simula" title="Simula">Simula</a> (a superset of ALGOL), and <a href="http://en.m.wikipedia.org/wiki/Kenneth_E._Iverson" title="Kenneth E. Iverson">Iverson</a>, the designer of <a href="http://en.m.wikipedia.org/wiki/APL_(programming_language)" title="APL (programming language)">APL</a> declared that the Burroughs implementation of APL was the best he'd seen.<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from February 2007">citation needed</span></a></i>]</sup><a href="http://en.m.wikipedia.org/wiki/John_McCarthy_(computer_scientist)" title="John McCarthy (computer scientist)">John McCarthy</a>, the language designer of <a href="http://en.m.wikipedia.org/wiki/LISP" title="LISP" class="mw-redirect">LISP</a> disagreed, since LISP was based on modifiable code<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from February 2007">citation needed</span></a></i>]</sup>, he did not like the unmodifiable code of the B5000<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from February 2007">citation needed</span></a></i>]</sup>, but most LISP implementations would run in an interpretive environment anyway.</p>
<p>Note also that the storage required for the multiple processes came from the system's memory pool as needed. There was no having to do SYSGENs on Burroughs systems as with competing systems in order to preconfigure <a href="http://en.m.wikipedia.org/wiki/Memory_management_(operating_systems)#Partitioned_allocation" title="Memory management (operating systems)">memory partitions</a> in which to run tasks.</p>
<h2> <span class="mw-headline" id="Tagged_architecture">Tagged architecture</span>
</h2>
<p>The most defining aspect of the B5000 is that it is a stack machine as treated above. However, two other very important features of the architecture is that it is <a href="http://en.m.wikipedia.org/wiki/Tagged_architecture" title="Tagged architecture">tag-based</a> and descriptor-based.</p>
<p>In the original B5000, a flag bit in each control or numeric word<sup id="cite_ref-16" class="reference"><a href="Burroughs_large_systems#cite_note-16"><span>[</span>12<span>]</span></a></sup> was set aside to identify the word as a control word or numeric word. This was partially a security mechanism to stop programs from being able to corrupt control words on the stack.</p>
<p>Later, when the B6500 was designed, it was realized that the 1-bit control word/numeric distinction was a powerful idea and this was extended to three bits outside of the 48 bit word into a tag. The data bits are bits 0-47 and the tag is in bits 48-50. Bit 48 was the read-only bit, thus odd tags indicated control words that could not be written by a user-level program. Code words were given tag 3. Here is a list of the tags and their function:</p>
<table class="wikitable">
<tr>
<th>Tag</th>
<th>Word kind</th>
<th>Description</th>
</tr>
<tr>
<td>0</td>
<td>Data</td>
<td>All kinds of user and system data (text data and single precision numbers)</td>
</tr>
<tr>
<td>2</td>
<td>Double</td>
<td>Double Precision data</td>
</tr>
<tr>
<td>4</td>
<td>SIW</td>
<td>Step Index word (used in loops)</td>
</tr>
<tr>
<td>6</td>
<td></td>
<td>Uninitialized data</td>
</tr>
<tr>
<td></td>
<td>SCW</td>
<td>Software Control Word (used to cut back the stack)</td>
</tr>
<tr>
<td>1</td>
<td>IRW</td>
<td>Indirect Reference Word</td>
</tr>
<tr>
<td></td>
<td>SIRW</td>
<td>Stuffed Indirect Reference Word</td>
</tr>
<tr>
<td>3</td>
<td>Code</td>
<td>Program code word</td>
</tr>
<tr>
<td></td>
<td>MSCW</td>
<td>Mark Stack Control Word</td>
</tr>
<tr>
<td></td>
<td>RCW</td>
<td>Return Control Word</td>
</tr>
<tr>
<td></td>
<td>TOSCW</td>
<td>Top of Stack Control Word</td>
</tr>
<tr>
<td></td>
<td>SD</td>
<td>Segment Descriptor</td>
</tr>
<tr>
<td>5</td>
<td>Descriptor</td>
<td>Data block descriptors</td>
</tr>
<tr>
<td>7</td>
<td>PCW</td>
<td>Program Control Word</td>
</tr>
</table>
<p>Note: Internally, some of the machines had 60 bit words, with the extra bits being used for engineering purposes such as a <a href="http://en.m.wikipedia.org/wiki/Hamming_code" title="Hamming code">Hamming code</a> error-correction field, but these were never seen by programmers.</p>
<p>Note: The current incarnation of these machines, the Unisys ClearPath has extended tags further into a four bit tag. The microcode level that specified four bit tags was referred to as level Gamma.</p>
<p>Even-tagged words are user data which can be modified by a user program as user state. Odd-tagged words are created and used directly by the hardware and represent a program's execution state. Since these words are created and consumed by specific instructions or the hardware, the exact format of these words can change between hardware implementation and user programs do not need to be recompiled, since the same code stream will produce the same results, even though system word format may have changed.</p>
<p>Tag 1 words represent on-stack data addresses. The normal IRW simply stores an address couple to data on the current stack. The SIRW references data on any stack by including a stack number in the address.</p>
<p>Tag 5 words are descriptors, which are more fully described in the next section. Tag 5 words represent off-stack data addresses.</p>
<p>Tag 7 is the program control word which describes a procedure entry point. When operators hit a PCW, the procedure is entered. The ENTR operator explicitly enters a procedure (non-value-returning routine). Functions (value-returning routines) are implicitly entered by operators such as value call (VALC). Note that global routines are stored in the D[2] environment as SIRWs that point to a PCW stored in the code segment dictionary in the D[1] environment. The D[1] environment is not stored on the current stack because it can be referenced by all processes sharing this code. Thus code is reentrant and shared.</p>
<p>Tag 3 represents code words themselves, which won't occur on the stack. Tag 3 is also used for the stack control words MSCW, RCW, TOSCW.</p>
<div class="thumb tleft">
<div class="thumbinner" style="width:422px;">
<a href="http://en.m.wikipedia.org/wiki/File:B6700Word.jpg" class="image"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/6/65/B6700Word.jpg/420px-B6700Word.jpg" width="420" height="324" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/en/thumb/6/65/B6700Word.jpg/630px-B6700Word.jpg 1.5x, //upload.wikimedia.org/wikipedia/en/6/65/B6700Word.jpg 2x"></a>
<div class="thumbcaption">

Figure 9.2 From the ACM Monograph in the References. <i><a href="http://en.m.wikipedia.org/wiki/Elliot_Organick" title="Elliot Organick" class="mw-redirect">Elliot Organick</a> 1973.</i>
</div>
</div>
</div>
<h2> <span class="mw-headline" id="Descriptor-based_architecture">Descriptor-based architecture</span>
</h2>
<p>The figure to the left shows how the Burroughs Large System architecture was fundamentally a hardware architecture for <a href="Object-oriented_programming" title="Object-oriented programming">Object-oriented programming</a>, something that still doesn't exist in conventional architectures.</p>
<div class="rellink relarticle mainarticle">Main article: <a href="http://en.m.wikipedia.org/wiki/Burroughs_large_systems_descriptors" title="Burroughs large systems descriptors">Burroughs large systems descriptors</a>
</div>
<h2> <span class="mw-headline" id="Instruction_set">Instruction set</span>
</h2>
<div class="rellink relarticle mainarticle">Main article: <a href="http://en.m.wikipedia.org/wiki/Burroughs_large_systems_instruction_set" title="Burroughs large systems instruction set" class="mw-redirect">Burroughs large systems instruction set</a>
</div>
<h2> <span class="mw-headline" id="Multiple_processors">Multiple processors</span>
</h2>
<p>The B5000 line also were pioneers in having multiple processors connected together on a high-speed bus. The B7000 line could have up to 8 processors, as long as at least one was an IO module. Note that RDLK is a very low-level way of synchronizing between processors. The high level used by user programs is the EVENT data type. The EVENT data type did have some system overhead. To avoid this overhead, a special locking technique called Dahm locks (named after a Burroughs software guru, Dave Dahm) can be used.</p>
<p>Notable operators are:</p>
<p><b>HEYU</b> — send an interrupt to another processor<br><b>RDLK</b> — Low-level semaphore operator: Load the A register with the memory location given by the A register and place the value in the B register at that memory location in a single uninterruptible cycle<br><b>WHOI</b> — Processor identification<br><b>IDLE</b> — Idle until an interrupt is received</p>
<p>Two processors could infrequently simultaneously send each other a 'HEYU' command resulting in a lockup known as 'a deadly embrace'.</p>
<h2> <span class="mw-headline" id="Influence_of_the_B5000">Influence of the B5000</span>
</h2>
<p>The direct influence of the B5000 can be seen in the current Unisys ClearPath range of mainframes which are the direct descendants of the B5000 and still have the MCP operating system after 40 years of consistent development. This architecture is now called emode (for emulation mode) since the B5000 architecture has been implemented on machines built from <a href="http://en.m.wikipedia.org/wiki/Intel_Xeon" title="Intel Xeon" class="mw-redirect">Intel Xeon</a> processors running the <a href="http://en.m.wikipedia.org/wiki/X86" title="X86">x86</a> instruction set as the native instruction set, with code running on those processors emulating the B5000 instruction set. In those machines, there was also going to be an nmode (<a href="http://en.m.wikipedia.org/wiki/Native_mode" title="Native mode" class="mw-redirect">native mode</a>), but this was dropped<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="http://en.m.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from September 2007">citation needed</span></a></i>]</sup>, so you may often hear the B5000 successor machines being referred to as "emode machines".</p>
<p>B5000 machines were programmed exclusively in high-level languages; there is no assembler.</p>
<p>The B5000 stack architecture inspired <a href="http://en.m.wikipedia.org/wiki/Chuck_Moore" title="Chuck Moore" class="mw-redirect">Chuck Moore</a>, the designer of the programming language <a href="http://en.m.wikipedia.org/wiki/Forth_(programming_language)" title="Forth (programming language)">Forth</a>, who encountered the B5500 while at MIT. In <a rel="nofollow" class="external text" href="http://www.colorforth.com/HOPL.html"><i>Forth - The Early Years</i></a>, Moore described the influence, noting that Forth's DUP, DROP and SWAP came from the corresponding B5500 instructions (DUPL, DLET, EXCH).</p>
<p>B5000 machines with their stack-based architecture and tagged memory also heavily influenced the Soviet <a href="http://en.m.wikipedia.org/wiki/Elbrus_(computer)" title="Elbrus (computer)">Elbrus</a> series of mainframes and <a href="Supercomputer" title="Supercomputer">supercomputers</a>. The first two generations of the series featured tagged memory and stack-based CPUs that were programmed only in high-level languages. There existed a kind of an <a href="Assembly_language" title="Assembly language">assembly language</a> for them, called El-76, but it was more or less a modification of <a href="http://en.m.wikipedia.org/wiki/ALGOL_60" title="ALGOL 60">ALGOL 60</a> and supported structured programming and first-class procedures. Later generations of the series, though, switched away from this architecture to the <a href="http://en.m.wikipedia.org/wiki/Explicitly_parallel_instruction_computing" title="Explicitly parallel instruction computing">EPIC</a>-like <a href="http://en.m.wikipedia.org/wiki/Elbrus_2000" title="Elbrus 2000">VLIW CPUs</a>.</p>
<p>The <a href="http://en.m.wikipedia.org/wiki/Hewlett-Packard" title="Hewlett-Packard">Hewlett-Packard</a> designers of the <a href="http://en.m.wikipedia.org/wiki/HP_3000" title="HP 3000">HP 3000</a> business system had used a B5500 and were greatly impressed by its hardware and software; they aimed to build a 16-bit minicomputer with similar software. Several other HP divisions created similar minicomputer or microprocessor stack machines. Bob Barton's work on <a href="http://en.m.wikipedia.org/wiki/Reverse_Polish_notation" title="Reverse Polish notation">reverse Polish notation</a> (RPN) also found its way into <a href="http://en.m.wikipedia.org/wiki/HP_calculators" title="HP calculators">HP calculators</a> beginning with the 9100A, and notably the <a href="http://en.m.wikipedia.org/wiki/HP-35" title="HP-35">HP-35</a> and subsequent calculators.</p>
<p>The NonStop systems designed by <a href="http://en.m.wikipedia.org/wiki/Tandem_Computers" title="Tandem Computers">Tandem Computers</a> in the late 1970s and early 1980s were also 16-bit stack machines, influenced by the B5000 indirectly through the HP 3000 connection, as several of the early Tandem engineers were formerly with HP. Around 1990, these systems migrated to MIPS RISC architecture but continued to support execution of stack machine binaries by object code translation or direct emulation. Sometime after 2000, these systems migrated to <a href="http://en.m.wikipedia.org/wiki/Itanium" title="Itanium">Itanium</a> architecture and continued to run the legacy stack machine binaries.</p>
<p>Bob Barton was also very influential on <a href="http://en.m.wikipedia.org/wiki/Alan_Kay" title="Alan Kay">Alan Kay</a>. Kay was also impressed by the data-driven tagged architecture of the B5000 and this influenced his thinking in his developments in object-oriented programming and <a href="Smalltalk" title="Smalltalk">Smalltalk</a>.</p>
<p>Another facet of the B5000 architecture was that it was a secure architecture that runs directly on hardware. This technique has descendants in the virtual machines of today in their attempts to provide secure environments. One notable such product is the Java JVM which provides a secure sandbox in which applications run.</p>
<p>The value of the hardware-architecture binding that existed before emode would be substantially preserved in the <a href="http://en.m.wikipedia.org/wiki/X86" title="X86">x86</a>-based machines to the extent that MCP was the one and only control program, but the support provided by those machines is still inferior to that provided on the machines where the B5000 instruction set is the native instruction set. A little-known Intel processor architecture that actually preceded 32-bit implementations of the x86 instruction set, the <a href="http://en.m.wikipedia.org/wiki/Intel_iAPX_432" title="Intel iAPX 432">Intel iAPX 432</a>, <i>would</i> have provided an equivalent physical basis, as it too was essentially an object oriented architecture.</p>
<h2> <span class="mw-headline" id="See_also">See also</span>
</h2>
<ul>
<li><a href="http://en.m.wikipedia.org/wiki/CANDE" title="CANDE">CANDE</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/Work_Flow_Language" title="Work Flow Language">WFL</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/Burroughs_B2500" title="Burroughs B2500">Burroughs Medium Systems</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/Burroughs_B1700" title="Burroughs B1700">Burroughs Small Systems</a></li>
</ul>
<h2> <span class="mw-headline" id="Notes">Notes</span>
</h2>
<div class="reflist" style="list-style-type: decimal;">
<ol class="references">
<li id="cite_note-1">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-1">^</a></b></span> <span class="reference-text">E.g., 12-bit for B5000, 8-bit for B6500</span>
</li>
<li id="cite_note-7">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-7">^</a></b></span> <span class="reference-text">There were security issues</span>
</li>
<li id="cite_note-8">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-8">^</a></b></span> <span class="reference-text">Unless you counted the <a href="http://en.m.wikipedia.org/wiki/Ferranti" title="Ferranti">Ferranti</a> <a href="http://en.m.wikipedia.org/wiki/Atlas_Computer_(Manchester)" title="Atlas Computer (Manchester)" class="mw-redirect">Atlas</a> as a commercial machine.</span>
</li>
<li id="cite_note-9">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-9">^</a></b></span> <span class="reference-text">Not counting error controls</span>
</li>
</ol>
</div>
<h2> <span class="mw-headline" id="References">References</span>
</h2>
<table class="metadata plainlinks ambox ambox-content ambox-Refimprove" style=""><tr>
<td class="mbox-image">
<div style="width: 52px;"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png" width="50" height="39" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x"></div>
</td>
<td class="mbox-text" style=""><span class="mbox-text-span">This article <b>needs additional <a href="Wikipedia:Citing_sources#Inline_citations" title="Wikipedia:Citing sources">citations</a> for <a href="Wikipedia:Verifiability" title="Wikipedia:Verifiability">verification</a></b>. <span class="hide-when-compact">Please help <a class="external text" href="http://en.wikipedia.org/w/index.php?title=Burroughs_large_systems&amp;action=edit">improve this article</a> by adding citations to <a href="http://en.m.wikipedia.org/wiki/Wikipedia:Identifying_reliable_sources" title="Wikipedia:Identifying reliable sources">reliable sources</a>. Unsourced material may be <a href="http://en.m.wikipedia.org/wiki/Template:Citation_needed" title="Template:Citation needed">challenged</a> and <a href="Wikipedia:Verifiability#Burden_of_evidence" title="Wikipedia:Verifiability">removed</a>.</span> <small><i>(November 2009)</i></small> </span></td>
</tr></table>
<ul>
<li>
<i>The Extended ALGOL Primer</i> (Three Volumes), Donald J. Gregory.</li>
<li>
<i>Computer Architecture: A Structured Approach,</i> R. Doran, Academic Press (1979).</li>
<li>
<i>Stack Computers: The New Wave,</i> Philip J. Koopman, available at: <a rel="nofollow" class="external autonumber" href="http://www.ece.cmu.edu/~koopman/stack_computers/index.html">[1]</a>
</li>
<li>B5500, B6500, B6700, B6800, B6900, B7700 manuals at: <a rel="nofollow" class="external text" href="http://www.bitsavers.org/pdf/burroughs/">bitsavers.org</a>
</li>
</ul>
<div class="reflist" style="list-style-type: decimal;">
<ol class="references">
<li id="cite_note-Da8500-2">
<span class="mw-cite-backlink">^ <a href="Burroughs_large_systems#cite_ref-Da8500_2-0"><sup><i><b>a</b></i></sup></a> <a href="Burroughs_large_systems#cite_ref-Da8500_2-1"><sup><i><b>b</b></i></sup></a> <a href="Burroughs_large_systems#cite_ref-Da8500_2-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><span class="citation Journal">John T. Lynch (August 1965), <a rel="nofollow" class="external text" href="http://bitsavers.org/pdf/burroughs/B8500/B8500_Datamation_Aug65.pdf">"The Burroughs B8500"</a>, <i>Datamation</i>: 49–50<span class="printonly">, <a rel="nofollow" class="external free" href="http://bitsavers.org/pdf/burroughs/B8500/B8500_Datamation_Aug65.pdf">http://bitsavers.org/pdf/burroughs/B8500/B8500_Datamation_Aug65.pdf</a></span>.</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=The+Burroughs+B8500&amp;rft.jtitle=Datamation&amp;rft.aulast=John+T.+Lynch&amp;rft.au=John+T.+Lynch&amp;rft.date=August+1965&amp;rft.pages=49%E2%80%9350&amp;rft_id=http%3A%2F%2Fbitsavers.org%2Fpdf%2Fburroughs%2FB8500%2FB8500_Datamation_Aug65.pdf&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-burroughs3g-3">
<span class="mw-cite-backlink">^ <a href="Burroughs_large_systems#cite_ref-burroughs3g_3-0"><sup><i><b>a</b></i></sup></a> <a href="Burroughs_large_systems#cite_ref-burroughs3g_3-1"><sup><i><b>b</b></i></sup></a> <a href="Burroughs_large_systems#cite_ref-burroughs3g_3-2"><sup><i><b>c</b></i></sup></a> <a href="Burroughs_large_systems#cite_ref-burroughs3g_3-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><span class="citation Journal">George Gray (October 1999), <a rel="nofollow" class="external text" href="https://wiki.cc.gatech.edu/folklore/index.php/Burroughs_Third-Generation_Computers">"Burroughs Third-Generation Computers"</a>, <i>Unisys History Newsletter</i> <b>3</b> (5)<span class="printonly">, <a rel="nofollow" class="external free" href="https://wiki.cc.gatech.edu/folklore/index.php/Burroughs_Third-Generation_Computers">https://wiki.cc.gatech.edu/folklore/index.php/Burroughs_Third-Generation_Computers</a></span>.</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Burroughs+Third-Generation+Computers&amp;rft.jtitle=Unisys+History+Newsletter&amp;rft.aulast=George+Gray&amp;rft.au=George+Gray&amp;rft.date=October+1999&amp;rft.volume=3&amp;rft.issue=5&amp;rft_id=https%3A%2F%2Fwiki.cc.gatech.edu%2Ffolklore%2Findex.php%2FBurroughs_Third-Generation_Computers&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-B5000-21005-4">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-B5000-21005_4-0">^</a></b></span> <span class="reference-text"><span class="citation manual">Burroughs (1963), <a rel="nofollow" class="external text" href="http://www.bitsavers.org/pdf/burroughs/B5000_5500_5700/5000-21005_B5000_operChar.pdf"><i>The Operational Characteristics of the Processors for the Burroughs B5000</i></a>, Revision A, 5000-21005<span class="printonly">, <a rel="nofollow" class="external free" href="http://www.bitsavers.org/pdf/burroughs/B5000_5500_5700/5000-21005_B5000_operChar.pdf">http://www.bitsavers.org/pdf/burroughs/B5000_5500_5700/5000-21005_B5000_operChar.pdf</a></span>.</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Operational+Characteristics+of+the+Processors+for+the+Burroughs+B5000&amp;rft.aulast=Burroughs&amp;rft.au=Burroughs&amp;rft.date=1963&amp;rft.series=Revision+A&amp;rft_id=http%3A%2F%2Fwww.bitsavers.org%2Fpdf%2Fburroughs%2FB5000_5500_5700%2F5000-21005_B5000_operChar.pdf&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-johnmashey-5">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-johnmashey_5-0">^</a></b></span> <span class="reference-text"><span class="citation newsgroup">John Mashey (2006-08-15). "<a rel="nofollow" class="external text" href="news:1155671202.964792.162180@b28g2000cwb.googlegroups.com">Admired designs / designs to study</a>". <a rel="nofollow" class="external text" href="news:comp.arch">comp.arch</a>. <a rel="nofollow" class="external text" href="http://groups.google.com/group/comp.arch/msg/8dcee778af867966">Web link</a><span class="reference-accessdate">. Retrieved 2007-12-15</span>.</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%5Bnews%3A1155671202.964792.162180%40b28g2000cwb.googlegroups.com+Admired+designs+%2F+designs+to+study%5D&amp;rft.atitle=&amp;rft.aulast=John+Mashey&amp;rft.au=John+Mashey&amp;rft.date=2006-08-15&amp;rft.pub=%5Bnews%3Acomp.arch+comp.arch%5D&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-B1021326-6">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-B1021326_6-0">^</a></b></span> <span class="reference-text"><span class="citation manual">Burroughs (May 1967), <a rel="nofollow" class="external text" href="http://www.bitsavers.org/pdf/burroughs/B5000_5500_5700/1021326_B5500_RefMan_May67.pdf"><i>Burroughs B5500 Information Processing System Reference Manual</i></a>, 1021326<span class="printonly">, <a rel="nofollow" class="external free" href="http://www.bitsavers.org/pdf/burroughs/B5000_5500_5700/1021326_B5500_RefMan_May67.pdf">http://www.bitsavers.org/pdf/burroughs/B5000_5500_5700/1021326_B5500_RefMan_May67.pdf</a></span>.</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Burroughs+B5500+Information+Processing+System+Reference+Manual&amp;rft.aulast=Burroughs&amp;rft.au=Burroughs&amp;rft.date=May+1967&amp;rft_id=http%3A%2F%2Fwww.bitsavers.org%2Fpdf%2Fburroughs%2FB5000_5500_5700%2F1021326_B5500_RefMan_May67.pdf&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-10">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-10">^</a></b></span> <span class="reference-text"><span class="citation book">Anderson, James P.; Hoffman, Samuel A.; Shifman, Joseph; Williams, Robert J. (1962), "D825 - a multiple-computer system for command &amp; control", <i>Proceedings of the December 4–6, 1962, Fall Joint Computer Conference</i>, AFIPS Conference Proceedings, <b>Volume 24</b>, <a href="Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1145%2F1461518.1461527">10.1145/1461518.1461527</a>.</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=D825+-+a+multiple-computer+system+for+command+%26+control&amp;rft.atitle=Proceedings+of+the+December+4%E2%80%936%2C+1962%2C+Fall+Joint+Computer+Conference&amp;rft.aulast=Anderson&amp;rft.aufirst=James+P.&amp;rft.au=Anderson%2C%26%2332%3BJames+P.&amp;rft.au=Hoffman%2C%26%2332%3BSamuel+A.&amp;rft.au=Shifman%2C%26%2332%3BJoseph&amp;rft.au=Williams%2C%26%2332%3BRobert+J.&amp;rft.date=1962&amp;rft.series=AFIPS+Conference+Proceedings&amp;rft.volume=Volume+24&amp;rft_id=info:doi/10.1145%2F1461518.1461527&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-11">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-11">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.classiccmp.org/dunfield/other/h/uascpu.jpg">SCAMP picture at dave's Old computers</a></span>
</li>
<li id="cite_note-12">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-12">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFReitman1989">Reitman, Valerie (January 18, 1989), <a rel="nofollow" class="external text" href="http://articles.philly.com/1989-01-18/business/26123789_1_unisys-scamp-mainframe">"Unisys Ready To Offer A Desktop Mainframe"</a>, <i><a href="http://en.m.wikipedia.org/wiki/Philadelphia_Inquirer" title="Philadelphia Inquirer" class="mw-redirect">Philadelphia Inquirer</a></i><span class="printonly">, <a rel="nofollow" class="external free" href="http://articles.philly.com/1989-01-18/business/26123789_1_unisys-scamp-mainframe">http://articles.philly.com/1989-01-18/business/26123789_1_unisys-scamp-mainframe</a></span><span class="reference-accessdate">, retrieved 2011-04-16</span></span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Unisys+Ready+To+Offer+A+Desktop+Mainframe&amp;rft.jtitle=%5B%5BPhiladelphia+Inquirer%5D%5D&amp;rft.aulast=Reitman&amp;rft.aufirst=Valerie&amp;rft.au=Reitman%2C%26%2332%3BValerie&amp;rft.date=January+18%2C+1989&amp;rft_id=http%3A%2F%2Farticles.philly.com%2F1989-01-18%2Fbusiness%2F26123789_1_unisys-scamp-mainframe&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-13">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-13">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.highbeam.com/doc/1G1-50063166.html">Unisys Accelerates Mainframe Rebirth with New ClearPath Enterprise Servers, Aggressive New Pricing. - Business Wire - HighBeam Research</a></span>
</li>
<li id="cite_note-14">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-14">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.unisys.com/products/mainframes/mcp__mainframes/earlier__mcp__models.htm">Libra 595</a></span>
</li>
<li id="cite_note-15">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-15">^</a></b></span> <span class="reference-text"><span class="citation book"><a href="http://en.m.wikipedia.org/wiki/Elliot_Organick" title="Elliot Organick" class="mw-redirect">Organick, Elliot</a> (1973). <i>Computer System Organization</i>. <a href="Association_for_Computing_Machinery" title="Association for Computing Machinery">ACM</a>. pp. 115–117. <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="http://en.m.wikipedia.org/wiki/Special:BookSources/0-12-528250-8" title="Special:BookSources/0-12-528250-8">0-12-528250-8</a>.</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computer+System+Organization&amp;rft.aulast=Organick&amp;rft.aufirst=Elliot&amp;rft.au=Organick%2C%26%2332%3BElliot&amp;rft.date=1973&amp;rft.pages=pp.%26nbsp%3B115%E2%80%93117&amp;rft.pub=%5B%5BAssociation+for+Computing+Machinery%7CACM%5D%5D&amp;rft.isbn=0-12-528250-8&amp;rfr_id=info:sid/en.wikipedia.org:Burroughs_large_systems"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-16">
<span class="mw-cite-backlink"><b><a href="Burroughs_large_systems#cite_ref-16">^</a></b></span> <span class="reference-text">There was no flag bit in words containing character data or code</span>
</li>
</ol>
</div>
<h2> <span class="mw-headline" id="Further_reading">Further reading</span>
</h2>
<ul>
<li>Barton, Robert S. "A New Approach to the Functional Design of a Digital Computer" Proceedings of the Western Joint Computer Conference. ACM (1961).</li>
<li>
<a rel="nofollow" class="external text" href="http://purl.umn.edu/107105">Burroughs B 5000 Oral history</a>, <a href="http://en.m.wikipedia.org/wiki/Charles_Babbage_Institute" title="Charles Babbage Institute">Charles Babbage Institute</a>, University of Minnesota. The Burroughs 5000 computer series is discussed by individuals responsible for its development and marketing from 1957 through the 1960s in a 1985 conference sponsored by <a href="http://en.m.wikipedia.org/wiki/American_Federation_of_Information_Processing_Societies" title="American Federation of Information Processing Societies">AFIPS</a> and <a href="http://en.m.wikipedia.org/wiki/Burroughs_Corporation" title="Burroughs Corporation">Burroughs Corporation</a>.</li>
<li>Gray, George. <a rel="nofollow" class="external text" href="https://wiki.cc.gatech.edu/folklore/index.php/Some_Burroughs_Transistor_Computers">"Some Burroughs Transistor Computers"</a>, Unisys History Newsletter, Volume 3, Number 1, March 1999.</li>
<li>Gray, George. <a rel="nofollow" class="external text" href="https://wiki.cc.gatech.edu/folklore/index.php/Burroughs_Third-Generation_Computers">"Burroughs Third-Generation Computers</a>, Unisys History Newsletter, Volume 3, Number 5, October 1999.</li>
<li>Hauck, E.A., Dent, Ben A. "Burroughs B6500/B7500 Stack Mechanism", SJCC (1968) pp. 245–251.</li>
<li>McKeeman, William M. "Language Directed Computer Design", Fall Joint Computer Conference, (1967) pp. 413–417.</li>
<li>Organick, Elliot I. <a rel="nofollow" class="external text" href="http://bitsavers.org/pdf/burroughs/B5000_5500_5700/Organick_B5700_B6700_1973.pdf">"Computer System Organization The B5700/B6700 series"</a>, Academic Press (1973).</li>
<li>Waychoff, Richard, <a rel="nofollow" class="external text" href="http://web.me.com/ianjoyner/Files/Waychoff.pdf">"Stories of the B5000 and People Who Were There"</a>, September 27, 1979.</li>
<li>Allweiss, Jack. <a rel="nofollow" class="external text" href="http://jack.hoa.org/hoajaa/BurrMain.html">"The Burroughs B5900 and E-Mode A bridge to 21st Century Computing"</a>, Revised 2010.</li>
</ul>
<h2> <span class="mw-headline" id="External_links">External links</span>
</h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://www.ianjoyner.name">Ian Joyner's Burroughs page</a></li>
<li>
<a rel="nofollow" class="external text" href="http://jack.hoa.org/hoajaa/b5900.htm">The Burroughs B5900 and E-Mode: A bridge to 21st Century Computing</a> - Jack Allweiss</li>
<li><a rel="nofollow" class="external text" href="http://users.monash.edu.au/~ralphk/burroughs.html">Ralph Klimek on the B7800 at Monash University</a></li>
<li>
<a rel="nofollow" class="external text" href="http://www.cs.virginia.edu/about/museum/">"Early Burroughs Machines"</a>, <a href="http://en.m.wikipedia.org/wiki/University_of_Virginia" title="University of Virginia">University of Virginia</a>'s Computer Museum.</li>
<li>
<a rel="nofollow" class="external text" href="http://bitsavers.org/pdf/burroughs/B5000_5500_5700/Organick_B5700_B6700_1973.pdf">"Computer System Organization"</a>, ACM Monograph Series.</li>
<li><a rel="nofollow" class="external text" href="http://bitsavers.org/pdf/burroughs/B8500/">Index of B8500 manuals</a></li>
<li>
<a rel="nofollow" class="external text" href="http://retro-b5500.blogspot.com/">B5500 Emulation Project</a> Project to create a functional emulator for the Burroughs B5500 computer system.</li>
<li><a rel="nofollow" class="external text" href="http://www.retrocomputingtasmania.com/home/projects/burroughs-b5500/b6500-film-transcript">"Burroughs B6500 film &amp; transcript"</a></li>
</ul>
<table cellspacing="0" class="navbox" style="border-spacing:0;;"><tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit;;">
<tr>
<th scope="col" style=";" class="navbox-title" colspan="2">
<div class="noprint plainlinks hlist navbar mini" style="">
<ul>
<li class="nv-view"><a href="http://en.m.wikipedia.org/wiki/Template:Unisys" title="Template:Unisys"><span title="View this template" style=";;background:none transparent;border:none;">v</span></a></li>
<li class="nv-talk"><span class="new" title="Template talk:Unisys (page does not exist)">t</span></li>
<li class="nv-edit"><a class="external text" href="http://en.wikipedia.org/w/index.php?title=Template:Unisys&amp;action=edit"><span title="Edit this template" style=";;background:none transparent;border:none;">e</span></a></li>
</ul>
</div>
<div class="" style="font-size:110%;"><a href="http://en.m.wikipedia.org/wiki/Unisys" title="Unisys">Unisys</a></div>
</th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Related articles</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd hlist">
<div style="padding:0em 0.25em">
<ul>
<li><a href="http://en.m.wikipedia.org/wiki/Burroughs_Corporation" title="Burroughs Corporation">Burroughs Corporation</a></li>
<li><strong class="selflink">Burroughs large systems</strong></li>
<li><a href="http://en.m.wikipedia.org/wiki/Eckert%E2%80%93Mauchly_Computer_Corporation" title="Eckert–Mauchly Computer Corporation">Eckert–Mauchly Computer Corporation</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/ES7000" title="ES7000">ES7000</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/List_of_UNIVAC_products" title="List of UNIVAC products">List of UNIVAC products</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/Sperry_Corporation" title="Sperry Corporation">Sperry Corporation</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/Sperry_Gyroscope_Company" title="Sperry Gyroscope Company" class="mw-redirect">Sperry Gyroscope Company</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/Unisys_MCP_programming_languages" title="Unisys MCP programming languages">Unisys MCP programming languages</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/UNIVAC_1100/2200_series" title="UNIVAC 1100/2200 series">UNIVAC 1100/2200 series</a></li>
<li><a href="http://en.m.wikipedia.org/wiki/UNIVAC_1107" title="UNIVAC 1107">UNIVAC 1107</a></li>
</ul>
</div>
</td>
</tr>
</table>
</td>
</tr></table>

						<div class="section" id="mw-mf-language-section">
				<h2 id="section_language" class="section_heading">Read in another language</h2>
				<div id="content_language" class="content_block">
					<p>This article is available in 3 languages</p>
					<ul id="mw-mf-language-selection"><li><a href="http://es.m.wikipedia.org/wiki/Grandes_sistemas_de_Burroughs" lang="es" hreflang="es">español</a></li><li><a href="http://ja.m.wikipedia.org/wiki/%E3%83%90%E3%83%AD%E3%83%BC%E3%82%B9_B5000" lang="ja" hreflang="ja">日本語</a></li><li><a href="http://no.m.wikipedia.org/wiki/Burroughs_stormaskiner" lang="no" hreflang="no">norsk (bokmål)‎</a></li></ul>
				</div>
			</div>			</div><!-- close #content_wrapper -->
			<div id="footer">
			<h2 class="section_heading" id="section_footer">
		<img src="http://bits.wikimedia.org/static-1.21wmf3/extensions/MobileFrontend/stylesheets/common/images/logo-copyright-en.png" class="license" alt="Wikipedia ®" />	</h2>
	<div class="content_block" id="content_footer">
		<ul class="settings">
			<li>
				<span class="left separator"><a id="mw-mf-display-toggle" href="http://en.wikipedia.org/w/index.php?title=Burroughs_large_systems&amp;mobileaction=toggle_view_desktop">Desktop</a></span><span class="right">Mobile</span>
			</li>
			<li class="notice">
				Article by <a href="http://en.m.wikipedia.org/w/index.php?title=Burroughs_large_systems&amp;action=history">contributors</a> like you<br>
				Content available under <a href="Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License?useformat=mobile">CC BY-SA 3.0</a>				<span>| <a href="http://wikimediafoundation.org/wiki/Terms_of_use?useformat=mobile">Terms of Use</a></span>
			</li>
		</ul>
		<ul class="links">
						<li>
			<a href='http://en.m.wikipedia.org/w/index.php?title=Special:MobileFeedback&amp;returnto=Burroughs+large+systems&amp;feedbacksource=MobileFrontend'>
				Contact Wikipedia			</a>
			</li><li>
						<a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy</a></li><li>
			<a href="Wikipedia:About" title="Wikipedia:About">About</a></li><li>
			<a href="Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		</ul>
	</div><!-- close footer.div / #content_footer -->
	</div><!-- close #footer -->
					</div><!-- close #mw-mf-page-center -->
		</div><!-- close #mw-mf-viewport -->
		
					</body>
	</html>